# Spark sink

Prior to Apache Spark 3.0, there were different approaches to expose metrics to Prometheus:

1. Using Spark’s JmxSink and Prometheus’s JMXExporter ([Monitoring Apache Spark on Kubernetes with Prometheus and Grafana](https://dzlab.github.io/data/2020/06/08/monitoring-spark-prometheus/))

- Enable Spark’s built-in JmxSink with $SPARK_HOME/conf/metrics.properties
- Deploy Prometheus’ JMXExporter library and its conﬁg ﬁle
- Expose JMXExporter port, 9091, to Prometheus Add -javaagent option to the target (master/worker/executor/driver)
```
./spark-submit \
... \
--conf spark.driver.extraJavaOptions=-javaagent:$SPARK_HOME/jars/jmx_prometheus_javaagent.jar=9091:$SPARK_HOME/conf/prometheus-config.yml \
...
```

2. Using Spark’s GraphiteSink and Prometheus’s [GraphiteExporter](https://github.com/prometheus/graphite_exporter)

- Set up Graphite server Enable Spark’s built-in
- Graphite Sink with several conﬁgurations
- Enable Prometheus’GraphiteExporter at Graphite

3. Using custom sinks and Prometheus’s [Pushgateway](https://www.metricfire.com/blog/prometheus-pushgateways-everything-you-need-to-know/)

- Set up Pushgateway server
- Develop a custom sink (or use 3rd party libs) with Prometheus dependency
- Deploy the sink libraries and its conﬁguration ﬁle to the cluster
