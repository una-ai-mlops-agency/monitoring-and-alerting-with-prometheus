# PromQL

The Prometheus Query Language offers you the ability to do all sorts of aggregations, analysis, and arithmetic, allowing you to better understand the performance of your systems from your metrics.

## Aggregation Basics
Let’s get started with some simple aggregation queries. These queries will likely cover most of your potential uses for PromQL. While PromQL is as powerful as it is possible to be, most of the time your needs will be reasonably simple.

### Gauge
Gauges are a snapshot of state, and usually when aggregating them you want to take a sum, average, minimum, or maximum.

Consider the metric node_filesystem_size_bytes from your Node exporter, which reports the size of each of your mounted filesystems, and has device, fstype, and mountpoint labels. You can calculate total filesystem size on each machine with:

```
sum without(device, fstype, mountpoint)(node_filesystem_size_bytes)
```

This works as without tells the sum aggregator to sum everything up with the same labels, ignoring those three.

You will notice that the device, fstype, and mountpoint labels are now gone. The metric name is also no longer present, as this is no longer node_filesystem_free_bytes as math has been performed on it. Since there is only one Node exporter being scraped by Prometheus there is only one result, but if you were scraping more then you would have a result for each of the Node exporters.

You could go a step further and remove the instance label with:

```
sum without(device, fstype, mountpoint, instance)(node_filesystem_size_bytes)
```

This as expected removes the instance label, but the value remains the same as the previous expression as there is only one Node exporter to aggregate metrics from

You can use the same approach with other aggregations. max would tell you the size of the biggest mounted filesystem on each machine:

```
max without(device, fstype, mountpoint)(node_filesystem_size_bytes)
```
You are not limited to aggregating metrics about one type of job. For example, to find the average number of file descriptors open across all your jobs you could use:

```
avg without(instance, job)(process_open_fds)
```

### Counter
Counters track the number or size of events, and the value your applications expose on their /metrics is the total since it started. But that total is of little use to you on its own, what you really want to know is how quickly the counter is increasing over time. This is usually done using the rate function, though the increase and irate functions also operate on counter values.

For example, to calculate the amount of network traffic received per second you could use:

```
rate(node_network_receive_bytes_total[5m])
```
The [5m] says to provide rate with 5 minutes of data, so the returned value will be an average over the last 5 minutes. The values here are not integers, as the 5-minute window rate is looking at does not perfectly align with the samples that Prometheus has scraped. Some estimation is used to fill in the gaps between the data points you have and the boundaries of the range.

The output of rate is a gauge, so the same aggregations apply as for gauges. The node_network_receive_bytes_total metric has a device label, so if you aggregate it away you will get the total bytes received per machine per second:

```
sum without(device)(rate(node_network_receive_bytes_total[5m]))
```

You can filter down which time series to request, so you could only look at eth0 and then aggregate it across all machines by aggregating away the instance label:

```
sum without(instance)(rate(node_network_receive_bytes_total{device="eth0"}[5m]))
```
There is no ordering or hierarchy within labels, allowing you to aggregate by as many or as few labels as you like.

### Summary
A summary metric will usually contain both a _sum and _count, and sometimes a time series with no suffix with a quantile label. The _sum and _count are both counters.

Your Prometheus exposes a http_response_size_bytes summary, for the amount of data some of its HTTP APIs return. http_response_size_bytes_count tracks the number of requests, and as it is a counter you must use rate before aggregating away its handler label:

```
sum without(handler)(rate(http_response_size_bytes_count[5m]))
```
This gives you the total per-second HTTP request rate.

Similarly, http_response_size_bytes_sum is a counter with the number of bytes each handle has returned, so the same pattern applies:

```
sum without(handler)(rate(http_response_size_bytes_sum[5m]))
```
This will return results with the same labels as the previous query, but the values are larger as responses tend to return many bytes.

The power of a summary is that it allows you to calculate the average size of an event, in this case the average amount of bytes that are being returned in each response. If you had three responses of size 1, 4, and 7, then the average would be their sum divided by their count, which is to say 12 divided by 3. The same applies to the summary. You divide the _sum by the _count (after taking a rate) to get an average over a time period:

```
  sum without(handler)(rate(http_response_size_bytes_sum[5m]))
/
  sum without(handler)(rate(http_response_size_bytes_count[5m]))
```
The division operator matches the time series with the same labels and divides, giving you the same two time series out but with the average response size over the past 5 minutes as a value.

When calculating an average, it is important that you first aggregate up the sum and count, and only as the last step perform the division. Otherwise, you could end up averaging averages, which is not statistically valid.

For example, if you wanted to get the average response size across all instances of a job, you could do:

```
  sum without(instance)(
    sum without(handler)(rate(http_response_size_bytes_sum[5m]))
  )
/
  sum without(instance)(
    sum without(handler)(rate(http_response_size_bytes_count[5m]))
  )
```
However, it’d be incorrect to do:

```
avg without(instance)(
    sum without(handler)(rate(http_response_size_bytes_sum[5m]))
  /
    sum without(handler)(rate(http_response_size_bytes_count[5m]))
)
```
It is incorrect to average an average, and both the division and avg would be calculating averages.

### Histogram
Histogram metrics allow you to track the distribution of the size of events, allowing you to calculate quantiles from them. For example, you can use histograms to calculate the 0.9 quantile (which is also known as the 90th percentile) latency.

Prometheus exposes a histogram metric called prometheus_tsdb_compaction_duration_seconds that tracks how many seconds compaction takes for the time series database. This histogram metric has time series with a _bucket suffix called prometheus_tsdb_compaction_duration_seconds_bucket. Each bucket has a le label, which is a counter of how many events have a size less than or equal to the bucket boundary. This is an implementation detail you largely need not worry about as the histogram_quantile function takes care of this when calculating quantiles. For example, the 0.90 quantile would be:

```
histogram_quantile(
    0.90,
    rate(prometheus_tsdb_compaction_duration_seconds_bucket[1d]))
```
As prometheus_tsdb_compaction_duration_seconds_bucket is a counter you must first take a rate. Compaction usually only happens every two hours, so a one-day time range is used here.

This indicates that the 90th percentile latency of compactions is around 7.72 seconds. As there will usually only be 12 compactions in a day, the 90th percentile says that 10% of compactions take longer than this, which is to say one or two compactions. This is something to be aware of when using quantiles. For example, if you want to calculate a 0.999 quantile you should have several thousand data points to work with in order to produce a reasonably accurate answer. If you have fewer than that, single outliers could greatly affect the result, and you should consider using lower quantiles to avoid making statements about your system that you have insufficient data to back up.

NOTE
Usually you would use a 5- or 10-minute rate with histograms. All the bucket time series combined with any labels, and a long range on the rate, can make for a lot of samples that need to be processed. Be wary of PromQL expressions using ranges that are hours or days, as they can be relatively expensive to calculate.4

Similar to when taking averages, using histogram_quantile should be the last step in a query expression. Quantiles cannot be aggregated, or have arithmetic performed upon them, from a statistical standpoint. Accordingly, when you want to take a histogram of an aggregate, first aggregate up with sum and then use histogram_quantile:

```
histogram_quantile(
  0.90,
  sum without(instance)(rate(prometheus_tsdb_compaction_duration_bucket[1d])))
```

This calculates the 0.9 quantile compaction duration across all of your Prometheus servers.

Histogram metrics also include _sum and _count metrics, which work exactly the same as for the summary metric. You can use these to calculate average event sizes, such as the average compaction duration:

```
  sum without(instance)(rate(prometheus_tsdb_compaction_duration_sum[1d]))
/
  sum without(instance)(rate(prometheus_tsdb_compaction_duration_count[1d]))
```

## Aggregation Operators

### Grouping

**without**

Generally you will always know the instrumentation labels, as they rarely change. But you do not always know the target labels in play, as an expression you write might be used by someone else on metrics originating from different scrape configs or Prometheus servers that might also have added in other target labels across a job, such as a env or cluster label. You might even add in such target labels yourself at some point, and it’d be nice not to have to update all your expressions.

When aggregating metrics you should usually try to preserve such target labels, and thus you should use the without clause when aggregating to specify the specific labels you want to remove. For example, the query:

```
sum without(fstype, mountpoint)(node_filesystem_size_bytes)
```
will group the time series, ignoring the fstype and mountpoint labels, into three groups and the sum aggregator will apply within each of these groups, adding up the values of the time series and return one sample per group:

Notice that the instance and job labels are preserved, as would be any other labels that had been present. This is useful because any alerts you created that included this expression somehow would have additional target labels like env or cluster preserved. This provides context for your alerts and makes them more useful (also useful when graphing).

The metric name has also been removed, as this is an aggregation of the node_filesystem_size_bytes metric rather than the original metric. When a PromQL operator or function could change the value or meaning of a time series, the metric name is removed.

**by**

In addition to without there is also the by clause. Where without specifies the labels to remove, by specifies the labels to keep. Accordingly, some care is required when using by to ensure you don’t remove target labels that you would like to propagate in your alerts or use in your dashboards. You cannot use both by and without in the same aggregation.

The query:

```
sum by(job, instance, device)(node_filesystem_size_bytes)
```
will produce the same result as the querying in the preceding section using without.

However, if instance or job had not been specified, then they wouldn’t have defined the group and would not be in the output. Generally, you should prefer to use without rather than by for this reason.

There are two cases where you might find by more useful. The first is that unlike without, by does not automatically drop the name label. This allows you to use expressions like:

```
sort_desc(count by(__name__)({__name__=~".+"}))
```

to investigate how many time series have the same metric names.

The second is cases where you do want to remove any labels you do not know about. For example, info metrics are expected to add more labels over time. To count how many machines were running each kernel version you could use:

```
count by(release)(node_uname_info)
```

### Operators
All 11 aggregation operators use the same grouping logic. You can control this with one of without or by. What differs between aggregation operators is what they do with the grouped data.

**sum**

sum is the most common aggregator; it adds up all the values in a group and returns that as the value for the group. For example:

```
sum without(fstype, mountpoint, device)(node_filesystem_size_bytes)
```
would return the total size of the filesystems of each of your machines.

When dealing with counters it is important that you take a rate before aggregating with sum:

```
sum without(device)(rate(node_disk_read_bytes_total[5m]))
```

If you were to take a sum across counters directly, the result would be meaningless, as different counters could have been initialised at different times depending on when the exporter started, restarted, or any particular children were first used.

**count**

The count aggregator counts the number of time series in a group, and returns it as the value for the group. For example:

```
count without(device)(node_disk_read_bytes_total)
```
would return the number of disk devices a machine has.
Here it is okay not to use rate with a counter, as you care about the existence of the time series rather than its value.

UNIQUE LABEL VALUES
You can also use count to count how many unique values a label has. For example, to count the number of CPUs in each of your machines you could use:

```
count without(cpu)(count without (mode)(node_cpu_seconds_total))
```
If you didn’t want a per-machine breakdown, such as if you were investigating if certain labels had high cardinality, you could use the by modifier to look at only one label:

```
count(count by(cpu)(node_cpu_seconds_total))
```

**avg**

The avg aggregator returns the average of the values4 of the time series in the group as the value for the group. For example:

```
avg without(cpu)(rate(node_cpu_seconds_total[5m]))
```
would give you the average usage of each CPU mode for each Node exporter instance

This gives you the exact same result as:

```
  sum without(cpu)(rate(node_cpu_seconds_total[5m]))
/
  count without(cpu)(rate(node_cpu_seconds_total[5m]))
```
but it is both more succinct and more efficient to use avg.

When using avg sometimes you may find that a NaN in the input is causing the entire result to become NaN. This is because any floating-point arithmetic that involves NaN will have NaN as a result.

You may wonder how to filter out these NaNs in the input, but that is the wrong question to ask. Usually this is due to attempting to average averages, which is not statistically valid, so what you should do instead is aggregate using sum and then finally divide, as shown in “Summary”.

**stddev and stdvar**

The standard deviation is a statistical measure of how spread out a set of numbers is. For example, if you had the numbers [2,4,6] then the standard deviation would be 1.633.6 The numbers [3,4,5] have the same average of 4, but a standard deviation of 0.816.

The main use of the standard deviation in monitoring is to detect outliers. In normally distributed data you would expect that about 68% of samples would be within one standard deviation of the mean, and 95% within two standard deviations.7 If one instance in a job has a metric several standard deviations away from the average, that’s a good indication that something is wrong with it.

For example, you could find all instances that were at least two standard deviations above the average using an expression such as:

```
  some_gauge
> ignoring (instance) group_left()
  (
      avg without(instance)(some_gauge)
    +
      2 * stddev without(instance)(some_gauge)
  )
```

If your values are all tightly bunched then this may return some time series that are more than two standard deviations away, but still operating normally and close to the average. You could add an additional filter that the value has to be at least say 20% higher than the average to protect against this. This is also a rare case where it is okay to take an average of an average, such as if you applied this to average latency.

The standard variance is the standard deviation squared and has statistical uses.

**min and max**

The min and max aggregators return the minimum or maximum value within a group as the value of the group, respectively. The same grouping rules apply as elsewhere, so the output time series will have the labels of the group. For example:

```
max without(device, fstype, mountpoint)(node_filesystem_size_bytes)
```
will return the size of the biggest filesystem on each instance.
The max and min aggregators will only return NaN if all values in a group are NaN.10

**topk and bottomk**

topk and bottomk are different from the other aggregators discussed so far in three ways. First, the labels of time series they return for a group are not the labels of the group; second, they can return more than one time series per group; and third, they take an additional parameter.

topk returns the k time series with the biggest values, so for example:

```
topk without(device, fstype, mountpoint)(2, node_filesystem_size_bytes)
```
would return up to two time series per group. As you can see, topk returns input time series with all their labels, including the name label, which holds the metric name. The result is also sorted.

bottomk is the same as topk, except that it returns the k time series with the smallest values rather than the k biggest values. Both aggregators will where possible avoid returning time series with NaN values.

**quantile**

The quantile aggregator returns the specified quantile of the values of the group as the group’s return value. As with topk, quantile takes a parameter.

So, for example, if I wanted to know across the different CPUs in each of my machines what the 90th percentile of the system mode CPU usage is I could use:

```
quantile without(cpu)(0.9, rate(node_cpu_seconds_total{mode="system"}[5m]))
```
This means that 90% of my CPUs are spending at least 0.02 seconds per second in the system mode. This would be a more useful query if I had tens of CPUs in my machine, rather than the four it actually has.

In addition to the mean, you could use quantile to show the median, 25th, and 75th percentiles12 on your graphs. For example, for process CPU usage the expressions would be:

- average, arithmetic mean
```
avg without(instance)(rate(process_cpu_seconds_total[5m]))
```

- 0.25 quantile, 25th percentile, 1st or lower quartile
```
quantile without(instance)(0.25, rate(process_cpu_seconds_total[5m]))
```

- 0.5 quantile, 50th percentile, 2nd quartile, median
```
quantile without(instance)(0.5, rate(process_cpu_seconds_total[5m]))
```

- 0.75 quantile, 75th percentile, 3rd or upper quartile
```
quantile without(instance)(0.75, rate(process_cpu_seconds_total[5m]))
```
This would give you a sense of how your different instances for a job are behaving, without having to graph each instance individually. This allows you to keep your dashboards readable as the number of underlying instances grows. Personally I find that per-instance graphs break down somewhere around three to five instances.

**count_values**

The final aggregation operator is count_values. Like topk it takes a parameter and can return more than one time series from a group. What it does is build a frequency histogram of the values of the time series in the group, with the count of each value as the value of the output time series and the original value as a new label.

Say you had a time series called software_version with the following values:

```
software_version{instance="a",job="j"} 7
software_version{instance="b",job="j"} 4
software_version{instance="c",job="j"} 8
software_version{instance="d",job="j"} 4
software_version{instance="e",job="j"} 7
software_version{instance="f",job="j"} 4
```

If you evaluated the query:

```
count_values without(instance)("version", software_version)
```
on these time series you would get the result:

```
{job="j",version="7"} 2
{job="j",version="8"} 1
{job="j",version="4"} 3
```

There were two time series in the group with a value of 7, so a time series with a version="7" plus the group labels was returned with the value 2. The result is similar for the other time series.

There is no bucketing involved when the frequency histogram is created; the exact values of the time series are used. Thus this is only really useful with integer values and where there will not be too many unique values.

This is most useful with version numbers or with the number of objects of some type that each instance of your application sees. If you have too many versions deployed at once, or different applications are continuing to see different numbers of objects, something might be stuck somewhere.

count_values can be combined with count to calculate the number of unique values for a given aggregation group. For example, the number of versions of software that are deployed can be calculated with:

```
count without(version)(
  count_values without(instance)("version", software_version)
)
```
You could also combine count_values with count in the other direction; for example, to see how many of your machines had how many disk devices:

```
count_values without(instance)(
  "devices",
  count without(device) (node_disk_io_now)
)
```

Learn more about [Binary Operators](https://prometheus.io/docs/prometheus/latest/querying/operators/) and [Functions](https://prometheus.io/docs/prometheus/latest/querying/functions/)